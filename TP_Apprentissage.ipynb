{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "71b2df1a",
      "metadata": {
        "id": "71b2df1a"
      },
      "source": [
        "# TP Apprentissage supervisé - Partie 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62f43f99",
      "metadata": {
        "id": "62f43f99"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "987cfe6a",
      "metadata": {
        "id": "987cfe6a"
      },
      "outputs": [],
      "source": [
        "feat_raw = pd.read_csv('acsincome_ca_features.csv')\n",
        "label_raw = pd.read_csv('acsincome_ca_labels.csv', usecols=['PINCP'])[['PINCP']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5573f2c",
      "metadata": {
        "id": "a5573f2c",
        "outputId": "5b8cb47a-7e2f-4791-8c47-5c20c3139ec7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AGEP</th>\n",
              "      <th>COW</th>\n",
              "      <th>SCHL</th>\n",
              "      <th>MAR</th>\n",
              "      <th>OCCP</th>\n",
              "      <th>POBP</th>\n",
              "      <th>RELP</th>\n",
              "      <th>WKHP</th>\n",
              "      <th>SEX</th>\n",
              "      <th>RAC1P</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>30.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9610.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1970.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>65.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2040.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>9610.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>18.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1021.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195660</th>\n",
              "      <td>38.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1021.0</td>\n",
              "      <td>210.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195661</th>\n",
              "      <td>39.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1021.0</td>\n",
              "      <td>210.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195662</th>\n",
              "      <td>61.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5240.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195663</th>\n",
              "      <td>69.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2040.0</td>\n",
              "      <td>207.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195664</th>\n",
              "      <td>40.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9600.0</td>\n",
              "      <td>303.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>195665 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        AGEP  COW  SCHL  MAR    OCCP   POBP  RELP  WKHP  SEX  RAC1P\n",
              "0       30.0  6.0  14.0  1.0  9610.0    6.0  16.0  40.0  1.0    8.0\n",
              "1       21.0  4.0  16.0  5.0  1970.0    6.0  17.0  20.0  1.0    1.0\n",
              "2       65.0  2.0  22.0  5.0  2040.0    6.0  17.0   8.0  1.0    1.0\n",
              "3       33.0  1.0  14.0  3.0  9610.0   36.0  16.0  40.0  1.0    1.0\n",
              "4       18.0  2.0  19.0  5.0  1021.0    6.0  17.0  18.0  2.0    1.0\n",
              "...      ...  ...   ...  ...     ...    ...   ...   ...  ...    ...\n",
              "195660  38.0  1.0  22.0  1.0  1021.0  210.0   0.0  40.0  1.0    6.0\n",
              "195661  39.0  1.0  22.0  1.0  1021.0  210.0   1.0  40.0  2.0    6.0\n",
              "195662  61.0  1.0  19.0  1.0  5240.0   17.0   0.0  45.0  1.0    1.0\n",
              "195663  69.0  7.0  24.0  1.0  2040.0  207.0   0.0  45.0  1.0    6.0\n",
              "195664  40.0  1.0  17.0  1.0  9600.0  303.0   0.0  40.0  1.0    8.0\n",
              "\n",
              "[195665 rows x 10 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feat_raw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d972100",
      "metadata": {
        "id": "0d972100",
        "outputId": "015e999c-e814-4b1d-b201-8f98a3bdff4d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PINCP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195660</th>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195661</th>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195662</th>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195663</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195664</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>195665 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        PINCP\n",
              "0       False\n",
              "1       False\n",
              "2       False\n",
              "3       False\n",
              "4       False\n",
              "...       ...\n",
              "195660   True\n",
              "195661   True\n",
              "195662   True\n",
              "195663  False\n",
              "195664  False\n",
              "\n",
              "[195665 rows x 1 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label_raw"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04158843",
      "metadata": {
        "id": "04158843"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43ecae4f",
      "metadata": {
        "id": "43ecae4f"
      },
      "outputs": [],
      "source": [
        "# There is no NA value.\n",
        "\n",
        "def preprocess(X_init, y_init, ratio=0.04):\n",
        "    # We normalize the ages\n",
        "    scaler = RobustScaler()\n",
        "    age_scaled = scaler.fit_transform(X_init[[\"AGEP\", \"WKHP\"]])\n",
        "    X_init[[\"AGEP\", \"WKHP\"]] = age_scaled\n",
        "\n",
        "    X_all, y_all = shuffle(X_init, y_init)\n",
        "\n",
        "    # only use the first N samples to limit training time\n",
        "    num_samples = int(len(X_all)*ratio)\n",
        "    X, y = X_all.head(num_samples), y_all.head(num_samples)\n",
        "\n",
        "\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a4e3e8b",
      "metadata": {
        "id": "9a4e3e8b"
      },
      "outputs": [],
      "source": [
        "X, y = preprocess(feat_raw, label_raw)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "y_train = y_train.to_numpy().reshape(1,-1)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a7bf090",
      "metadata": {
        "id": "2a7bf090",
        "outputId": "e8135df2-3e63-4367-a984-ad6816a4529c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AGEP</th>\n",
              "      <th>COW</th>\n",
              "      <th>SCHL</th>\n",
              "      <th>MAR</th>\n",
              "      <th>OCCP</th>\n",
              "      <th>POBP</th>\n",
              "      <th>RELP</th>\n",
              "      <th>WKHP</th>\n",
              "      <th>SEX</th>\n",
              "      <th>RAC1P</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>77375</th>\n",
              "      <td>-0.76</td>\n",
              "      <td>1.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4840.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77285</th>\n",
              "      <td>-0.84</td>\n",
              "      <td>6.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2722.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>-4.375</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154926</th>\n",
              "      <td>0.16</td>\n",
              "      <td>1.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8140.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138152</th>\n",
              "      <td>0.60</td>\n",
              "      <td>1.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8610.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.625</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127038</th>\n",
              "      <td>-0.60</td>\n",
              "      <td>1.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>9130.0</td>\n",
              "      <td>303.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29884</th>\n",
              "      <td>1.04</td>\n",
              "      <td>3.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2310.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-4.000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51909</th>\n",
              "      <td>-0.28</td>\n",
              "      <td>1.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1021.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.625</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138288</th>\n",
              "      <td>0.04</td>\n",
              "      <td>1.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>440.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.250</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89604</th>\n",
              "      <td>0.84</td>\n",
              "      <td>7.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>220.0</td>\n",
              "      <td>139.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.250</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109287</th>\n",
              "      <td>-0.12</td>\n",
              "      <td>1.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7340.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6260 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        AGEP  COW  SCHL  MAR    OCCP   POBP  RELP   WKHP  SEX  RAC1P\n",
              "77375  -0.76  1.0  21.0  5.0  4840.0    6.0   2.0  0.000  1.0    8.0\n",
              "77285  -0.84  6.0  16.0  5.0  2722.0    6.0   4.0 -4.375  1.0    1.0\n",
              "154926  0.16  1.0  16.0  3.0  8140.0    6.0   0.0  0.000  1.0    1.0\n",
              "138152  0.60  1.0  16.0  1.0  8610.0    6.0   0.0  0.625  1.0    1.0\n",
              "127038 -0.60  1.0  16.0  5.0  9130.0  303.0   2.0  0.000  1.0    8.0\n",
              "...      ...  ...   ...  ...     ...    ...   ...    ...  ...    ...\n",
              "29884   1.04  3.0  21.0  1.0  2310.0    6.0   1.0 -4.000  2.0    1.0\n",
              "51909  -0.28  1.0  21.0  1.0  1021.0    6.0   1.0  0.625  2.0    6.0\n",
              "138288  0.04  1.0  18.0  1.0   440.0    6.0   1.0  1.250  1.0    1.0\n",
              "89604   0.84  7.0  19.0  1.0   220.0  139.0   0.0  1.250  1.0    1.0\n",
              "109287 -0.12  1.0  19.0  1.0  7340.0   51.0   9.0  0.000  1.0    1.0\n",
              "\n",
              "[6260 rows x 10 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b7cb3ac",
      "metadata": {
        "id": "7b7cb3ac"
      },
      "source": [
        "# SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9c85d37",
      "metadata": {
        "id": "a9c85d37",
        "outputId": "2fda50a4-ab2f-4248-8a9e-f28fe353e807"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.70926518 0.72364217 0.7172524  0.71325879 0.72284345]\n"
          ]
        }
      ],
      "source": [
        "# SVM, RandomForest, AdaBoost et GradientBoosting\n",
        "model = SVC()\n",
        "cv_results = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
        "print(cv_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e982c75b",
      "metadata": {
        "id": "e982c75b",
        "outputId": "4171f692-0f93-450f-dfec-8d11301e8572"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.69      0.83      0.75       899\n",
            "        True       0.68      0.49      0.57       667\n",
            "\n",
            "    accuracy                           0.69      1566\n",
            "   macro avg       0.68      0.66      0.66      1566\n",
            "weighted avg       0.69      0.69      0.68      1566\n",
            "\n",
            "-----------------------------------\n",
            "[[746 153]\n",
            " [339 328]]\n"
          ]
        }
      ],
      "source": [
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"-----------------------------------\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "# [[TP, FN],\n",
        "#  [FP, TN]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd73d60e",
      "metadata": {
        "id": "dd73d60e",
        "outputId": "48fd3758-1e8c-4aa9-cdec-cdbec86cf705"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'C': 0.006473082037010402, 'degree': 2, 'kernel': 'rbf'}\n",
            "0.7218849840255591\n"
          ]
        }
      ],
      "source": [
        "params = {'kernel': ['poly', 'rbf', 'sigmoid'],\n",
        "         'degree': [2,3],\n",
        "         'C': np.logspace(-2.3, -1.3, 10)}\n",
        "\n",
        "gsv = GridSearchCV(SVC(), param_grid=params, cv=5)\n",
        "gsv.fit(X_train, y_train)\n",
        "\n",
        "print(gsv.best_params_)\n",
        "print(gsv.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8f244f3",
      "metadata": {
        "id": "d8f244f3",
        "outputId": "4f59fd45-ee57-4940-fd38-1a4c873bbb4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.67      0.87      0.76       899\n",
            "        True       0.70      0.43      0.54       667\n",
            "\n",
            "    accuracy                           0.68      1566\n",
            "   macro avg       0.69      0.65      0.65      1566\n",
            "weighted avg       0.69      0.68      0.66      1566\n",
            "\n",
            "-----------------------------------\n",
            "[[778 121]\n",
            " [378 289]]\n"
          ]
        }
      ],
      "source": [
        "model = gsv.best_estimator_\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"-----------------------------------\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "# [[TP, FN],\n",
        "#  [FP, TN]]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfb277d4",
      "metadata": {
        "id": "cfb277d4"
      },
      "source": [
        "# RandomForest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50a34532",
      "metadata": {
        "id": "50a34532"
      },
      "outputs": [],
      "source": [
        "X, y = preprocess(feat_raw, label_raw, 0.01)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "y_train = y_train.to_numpy().reshape(1,-1)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dacda698",
      "metadata": {
        "id": "dacda698",
        "outputId": "f03c78b5-2f91-43f7-ba93-0e3ad1572c9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.79552716 0.79872204 0.78594249 0.77635783 0.78525641]\n"
          ]
        }
      ],
      "source": [
        "model = RandomForestClassifier()\n",
        "cv_results = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
        "print(cv_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b4f49fc",
      "metadata": {
        "id": "5b4f49fc",
        "outputId": "eb8e42a2-d3f4-4a3e-91c3-028390260cc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.83      0.87      0.85       242\n",
            "        True       0.77      0.71      0.74       150\n",
            "\n",
            "    accuracy                           0.81       392\n",
            "   macro avg       0.80      0.79      0.79       392\n",
            "weighted avg       0.80      0.81      0.80       392\n",
            "\n",
            "-----------------------------------\n",
            "[[210  32]\n",
            " [ 44 106]]\n"
          ]
        }
      ],
      "source": [
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"-----------------------------------\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "# [[TP, FN],\n",
        "#  [FP, TN]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7d9cb98",
      "metadata": {
        "id": "f7d9cb98",
        "outputId": "981a9dc3-cc3c-45f8-9eb3-4ab4e8083c7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'criterion': 'entropy', 'max_depth': 8, 'min_samples_split': 2, 'n_estimators': 50, 'n_jobs': -1}\n",
            "0.8011468829360202\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/insa/anaconda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "450 fits failed out of a total of 2250.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "450 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/insa/anaconda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/insa/anaconda/lib/python3.11/site-packages/sklearn/ensemble/_forest.py\", line 340, in fit\n",
            "    self._validate_params()\n",
            "  File \"/usr/local/insa/anaconda/lib/python3.11/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/insa/anaconda/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 'None' instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/insa/anaconda/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.75766364 0.75894773 0.76533546 0.76532932 0.75830671 0.75958262\n",
            " 0.75830261 0.76596625 0.75958466 0.76085852 0.75830261 0.7544667\n",
            " 0.76342058 0.76213648 0.76404727 0.76470058 0.76277546 0.76661342\n",
            " 0.76405341 0.76085648 0.75894159 0.77108421 0.76405956 0.76277955\n",
            " 0.76405136 0.75893749 0.76405546 0.76086262 0.76276931 0.76917752\n",
            " 0.78068731 0.77940321 0.78068936 0.77493446 0.77940321 0.78642992\n",
            " 0.78324117 0.78004628 0.78323913 0.78451503 0.78068526 0.77876219\n",
            " 0.78772016 0.7851622  0.7755632  0.78579913 0.77876014 0.78004219\n",
            " 0.77940731 0.78324322 0.77684116 0.78644016 0.78132424 0.77620832\n",
            " 0.77939912 0.78324527 0.78132629 0.78259605 0.77812526 0.77748218\n",
            " 0.79283403 0.78004833 0.78708118 0.7864463  0.79091505 0.79155198\n",
            " 0.79219096 0.79219096 0.79346686 0.79411198 0.79154993 0.7851663\n",
            " 0.79475301 0.78771402 0.78963709 0.78963095 0.78771811 0.79155198\n",
            " 0.792193   0.79858892 0.7909089  0.78899402 0.79603506 0.79475506\n",
            " 0.79027198 0.79282993 0.78898992 0.79538175 0.79219505 0.79283403\n",
            " 0.78836528 0.77940526 0.78708323 0.7781314  0.78580118 0.79028017\n",
            " 0.78643811 0.78644221 0.78835299 0.78132219 0.79284427 0.78836938\n",
            " 0.78708528 0.78772221 0.78324937 0.7909171  0.79092119 0.78963709\n",
            " 0.79091505 0.79219505 0.78260834 0.78708323 0.78836323 0.79091095\n",
            " 0.79028426 0.79026174 0.78963505 0.78579913 0.79155198 0.78325141\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.75063079 0.75446056 0.76980831 0.75958057 0.76341034 0.76789342\n",
            " 0.76342263 0.76470263 0.75765954 0.76342058 0.76852626 0.76405956\n",
            " 0.75893749 0.76405751 0.75765954 0.76917138 0.76661751 0.76469853\n",
            " 0.76341853 0.76085648 0.76215286 0.76213648 0.76214467 0.75638158\n",
            " 0.76532932 0.75894364 0.75894364 0.7627775  0.76662161 0.76597649\n",
            " 0.78132219 0.78132014 0.78005038 0.78132424 0.78005448 0.78004628\n",
            " 0.78451913 0.7781273  0.77940731 0.77876219 0.78452527 0.780034\n",
            " 0.77364217 0.77493242 0.78068936 0.77940526 0.77812526 0.78516425\n",
            " 0.78068321 0.78004219 0.7768473  0.78324322 0.78260424 0.77812935\n",
            " 0.78068117 0.78068321 0.77428525 0.77877447 0.78068526 0.78771811\n",
            " 0.78708323 0.79475096 0.79027812 0.79411198 0.789633   0.79411198\n",
            " 0.79283198 0.79474891 0.79538175 0.79603097 0.79346686 0.790913\n",
            " 0.78963095 0.78963505 0.79091095 0.79218891 0.79410994 0.78899607\n",
            " 0.79347096 0.79410789 0.78963709 0.79091095 0.79794995 0.7909089\n",
            " 0.79410789 0.78899607 0.79922176 0.79027402 0.79155607 0.79410584\n",
            " 0.78772426 0.78579913 0.78964119 0.78772016 0.78644016 0.79411198\n",
            " 0.78324527 0.78324527 0.78707913 0.79155812 0.78708118 0.78964733\n",
            " 0.78772426 0.78771402 0.78452527 0.7934771  0.78771811 0.78388629\n",
            " 0.79156427 0.78579913 0.79091914 0.79476325 0.78580323 0.78643606\n",
            " 0.79027607 0.79283198 0.78962481 0.78771606 0.79027198 0.78836323\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.7570308  0.75830057 0.76917138 0.76406365 0.76085852 0.76213648\n",
            " 0.76087081 0.76597034 0.75382977 0.75639182 0.76597034 0.76470058\n",
            " 0.76405956 0.75766159 0.76405956 0.76085852 0.7570308  0.75766568\n",
            " 0.76533546 0.76022364 0.76469444 0.75894978 0.75446875 0.76149955\n",
            " 0.75830466 0.76406365 0.7653457  0.76916523 0.76342263 0.76917547\n",
            " 0.77620832 0.79155812 0.7768514  0.77812935 0.77365036 0.77876423\n",
            " 0.77940116 0.78068731 0.78516425 0.78260424 0.78195912 0.78579913\n",
            " 0.77748423 0.78132219 0.77940936 0.77940526 0.78132014 0.77877243\n",
            " 0.78196731 0.78324322 0.78068526 0.78516835 0.77557754 0.78196322\n",
            " 0.78004833 0.77877447 0.78707913 0.78132219 0.78196322 0.78388425\n",
            " 0.80114688 0.79858688 0.79347915 0.79475506 0.7921971  0.7851622\n",
            " 0.79218891 0.78898992 0.792193   0.79730892 0.79410994 0.79410789\n",
            " 0.78835709 0.79667199 0.79155403 0.78899812 0.79602892 0.79411198\n",
            " 0.7909171  0.79155403 0.7826022  0.78643811 0.79538994 0.78580118\n",
            " 0.79411403 0.79028017 0.79219505 0.79026993 0.79283403 0.78899402\n",
            " 0.78069141 0.78644425 0.78708323 0.79028017 0.78323708 0.78772221\n",
            " 0.79091914 0.79283608 0.78772016 0.79283403 0.78837347 0.78644835\n",
            " 0.78836119 0.78708118 0.79156017 0.78964529 0.7909171  0.79155812\n",
            " 0.79411608 0.79283608 0.78517039 0.78835504 0.79219915 0.78580937\n",
            " 0.789633   0.78579708 0.79026993 0.78836323 0.79155812 0.79347506]\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "params = {'n_estimators': np.arange(50,150,10),\n",
        "         'criterion': ['gini', 'log_loss', 'entropy'],\n",
        "          'max_depth': ['None', 2,4,8,10],\n",
        "         'min_samples_split': [2,3,4],\n",
        "         'n_jobs':[-1]}\n",
        "\n",
        "gsv = GridSearchCV(RandomForestClassifier(), param_grid=params, cv=5)\n",
        "gsv.fit(X_train, y_train)\n",
        "\n",
        "print(gsv.best_params_)\n",
        "print(gsv.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b8dca3e",
      "metadata": {
        "id": "7b8dca3e",
        "outputId": "ec9657eb-544f-44c2-e622-98cddd055820"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.85      0.86      0.86       242\n",
            "        True       0.78      0.76      0.77       150\n",
            "\n",
            "    accuracy                           0.82       392\n",
            "   macro avg       0.81      0.81      0.81       392\n",
            "weighted avg       0.82      0.82      0.82       392\n",
            "\n",
            "-----------------------------------\n",
            "[[209  33]\n",
            " [ 36 114]]\n"
          ]
        }
      ],
      "source": [
        "model = gsv.best_estimator_\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"-----------------------------------\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "# [[TP, FN],\n",
        "#  [FP, TN]]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2541c22",
      "metadata": {
        "id": "b2541c22"
      },
      "source": [
        "# Adaboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64a9521e",
      "metadata": {
        "id": "64a9521e"
      },
      "outputs": [],
      "source": [
        "X, y = preprocess(feat_raw, label_raw, 0.01)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "y_train = y_train.to_numpy().reshape(1,-1)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f3e2e95",
      "metadata": {
        "id": "5f3e2e95",
        "outputId": "31a8127f-9586-4c8e-e33a-7ee55cdf9986"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.76357827 0.83386581 0.77955272 0.76357827 0.76282051]\n"
          ]
        }
      ],
      "source": [
        "model = AdaBoostClassifier()\n",
        "cv_results = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
        "print(cv_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d330f33",
      "metadata": {
        "id": "1d330f33",
        "outputId": "48593f92-2fd5-4428-b5ab-5c228a92ac14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.79      0.83      0.81       219\n",
            "        True       0.77      0.73      0.75       173\n",
            "\n",
            "    accuracy                           0.79       392\n",
            "   macro avg       0.78      0.78      0.78       392\n",
            "weighted avg       0.79      0.79      0.78       392\n",
            "\n",
            "-----------------------------------\n",
            "[[182  37]\n",
            " [ 47 126]]\n"
          ]
        }
      ],
      "source": [
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"-----------------------------------\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "# [[TP, FN],\n",
        "#  [FP, TN]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb936044",
      "metadata": {
        "id": "fb936044",
        "outputId": "59c49d46-a4d5-47d2-ea62-cc6f593944e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'algorithm': 'SAMME.R', 'learning_rate': 0.030045385302046933, 'n_estimators': 70}\n",
            "0.779401163266978\n"
          ]
        }
      ],
      "source": [
        "params = {'n_estimators': np.arange(50,150,10),\n",
        "         'learning_rate': np.logspace(-2.3, -1.3, 10),\n",
        "          'algorithm': ['SAMME', 'SAMME.R']\n",
        "         }\n",
        "\n",
        "gsv = GridSearchCV(AdaBoostClassifier(), param_grid=params, cv=5)\n",
        "gsv.fit(X_train, y_train)\n",
        "\n",
        "print(gsv.best_params_)\n",
        "print(gsv.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52ee26f8",
      "metadata": {
        "id": "52ee26f8",
        "outputId": "9d2da2e4-1f83-45eb-cdb7-105778d15fe5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.73      0.86      0.79       219\n",
            "        True       0.77      0.61      0.68       173\n",
            "\n",
            "    accuracy                           0.75       392\n",
            "   macro avg       0.75      0.73      0.74       392\n",
            "weighted avg       0.75      0.75      0.74       392\n",
            "\n",
            "-----------------------------------\n",
            "[[188  31]\n",
            " [ 68 105]]\n"
          ]
        }
      ],
      "source": [
        "model = gsv.best_estimator_\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"-----------------------------------\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "# [[TP, FN],\n",
        "#  [FP, TN]]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8f77895",
      "metadata": {
        "id": "d8f77895"
      },
      "source": [
        "# GradientBoosting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28c2f579",
      "metadata": {
        "id": "28c2f579"
      },
      "outputs": [],
      "source": [
        "X, y = preprocess(feat_raw, label_raw, 0.01)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "y_train = y_train.to_numpy().reshape(1,-1)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc8fe11a",
      "metadata": {
        "id": "bc8fe11a",
        "outputId": "8cbb58a4-3fa8-43a5-b7a4-9a129e94b5a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.79233227 0.81789137 0.78594249 0.80511182 0.81089744]\n"
          ]
        }
      ],
      "source": [
        "model = GradientBoostingClassifier()\n",
        "cv_results = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
        "print(cv_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e488d2f6",
      "metadata": {
        "id": "e488d2f6",
        "outputId": "b0cbaf5e-fb74-4e80-866f-2e6dd4740750"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.82      0.85      0.84       222\n",
            "        True       0.79      0.76      0.78       170\n",
            "\n",
            "    accuracy                           0.81       392\n",
            "   macro avg       0.81      0.81      0.81       392\n",
            "weighted avg       0.81      0.81      0.81       392\n",
            "\n",
            "-----------------------------------\n",
            "[[188  34]\n",
            " [ 40 130]]\n"
          ]
        }
      ],
      "source": [
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"-----------------------------------\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "# [[TP, FN],\n",
        "#  [FP, TN]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8220356a",
      "metadata": {
        "id": "8220356a",
        "outputId": "c593942e-49a1-4ce5-ae59-d311f1a65c4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'criterion': 'friedman_mse', 'learning_rate': 0.030045385302046933, 'loss': 'exponential', 'n_estimators': 120}\n",
            "0.8075509953305481\n"
          ]
        }
      ],
      "source": [
        "params = {'loss': ['log_loss', 'exponential'],\n",
        "         'learning_rate': np.logspace(-2.3, -1.3, 10),\n",
        "          'n_estimators': np.arange(50,150,10),\n",
        "         'criterion':['friedman_mse', 'squared_error']}\n",
        "\n",
        "gsv = GridSearchCV(GradientBoostingClassifier(), param_grid=params, cv=5)\n",
        "gsv.fit(X_train, y_train)\n",
        "\n",
        "print(gsv.best_params_)\n",
        "print(gsv.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "912ee811",
      "metadata": {
        "id": "912ee811",
        "outputId": "899999f2-87db-4ae7-a4db-1eaa05f5a45f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.81      0.85      0.83       222\n",
            "        True       0.79      0.75      0.77       170\n",
            "\n",
            "    accuracy                           0.81       392\n",
            "   macro avg       0.80      0.80      0.80       392\n",
            "weighted avg       0.81      0.81      0.81       392\n",
            "\n",
            "-----------------------------------\n",
            "[[189  33]\n",
            " [ 43 127]]\n"
          ]
        }
      ],
      "source": [
        "model = gsv.best_estimator_\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"-----------------------------------\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "# [[TP, FN],\n",
        "#  [FP, TN]]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "143fdd6c",
      "metadata": {
        "id": "143fdd6c"
      },
      "source": [
        "# Collecting the best models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef30ddde",
      "metadata": {
        "id": "ef30ddde"
      },
      "outputs": [],
      "source": [
        "X, y = preprocess(feat_raw, label_raw, 0.04)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "y_train = y_train.to_numpy().reshape(1,-1)[0]\n",
        "\n",
        "best_GB = GradientBoostingClassifier(criterion='friedman_mse', learning_rate=0.03880510732210184,\n",
        "                                     loss='exponential', n_estimators=130)\n",
        "\n",
        "best_AB = AdaBoostClassifier(algorithm='SAMME.R', learning_rate=0.05011872336272722, n_estimators=140)\n",
        "\n",
        "best_RF = RandomForestClassifier(criterion='entropy', max_depth=10, min_samples_split=2, n_estimators=130, n_jobs=-1)\n",
        "\n",
        "best_SVM = SVC(C=0.0107977516232771, degree=2, kernel='rbf')\n",
        "\n",
        "best_models = [best_GB, best_AB, best_RF, best_SVM]\n",
        "\n",
        "for model in best_models:\n",
        "    model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f854658e",
      "metadata": {
        "id": "f854658e",
        "outputId": "33408208-a2d4-4410-bc70-249d02db7719"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===================================\n",
            "GradientBoostingClassifier(learning_rate=0.03880510732210184,\n",
            "                           loss='exponential', n_estimators=130)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.70      0.77       289\n",
            "           1       0.56      0.77      0.65       142\n",
            "\n",
            "    accuracy                           0.73       431\n",
            "   macro avg       0.71      0.74      0.71       431\n",
            "weighted avg       0.76      0.73      0.73       431\n",
            "\n",
            "-----------------------------------\n",
            "[[203  86]\n",
            " [ 32 110]]\n",
            "===================================\n",
            "AdaBoostClassifier(learning_rate=0.05011872336272722, n_estimators=140)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.72      0.77       289\n",
            "           1       0.55      0.69      0.61       142\n",
            "\n",
            "    accuracy                           0.71       431\n",
            "   macro avg       0.69      0.71      0.69       431\n",
            "weighted avg       0.74      0.71      0.72       431\n",
            "\n",
            "-----------------------------------\n",
            "[[209  80]\n",
            " [ 44  98]]\n",
            "===================================\n",
            "RandomForestClassifier(criterion='entropy', max_depth=10, n_estimators=130,\n",
            "                       n_jobs=-1)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.67      0.76       289\n",
            "           1       0.55      0.82      0.66       142\n",
            "\n",
            "    accuracy                           0.72       431\n",
            "   macro avg       0.72      0.74      0.71       431\n",
            "weighted avg       0.77      0.72      0.73       431\n",
            "\n",
            "-----------------------------------\n",
            "[[194  95]\n",
            " [ 26 116]]\n",
            "===================================\n",
            "SVC(C=0.0107977516232771, degree=2)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.81      0.78       289\n",
            "           1       0.54      0.47      0.51       142\n",
            "\n",
            "    accuracy                           0.70       431\n",
            "   macro avg       0.65      0.64      0.64       431\n",
            "weighted avg       0.69      0.70      0.69       431\n",
            "\n",
            "-----------------------------------\n",
            "[[233  56]\n",
            " [ 75  67]]\n"
          ]
        }
      ],
      "source": [
        "# Go search the rest of the data\n",
        "feat_ne = pd.read_csv('acsincome_ne_allfeaturesTP2.csv')\n",
        "label_ne = pd.read_csv('acsincome_ne_labelTP2.csv', usecols=['PINCP'])[['PINCP']]\n",
        "\n",
        "\n",
        "X_ne, y_ne = preprocess(feat_ne, label_ne)\n",
        "\n",
        "for model in best_models:\n",
        "    print(\"===================================\")\n",
        "    print(model)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_pred_ne = model.predict(X_ne)\n",
        "    print(classification_report(y_ne, y_pred_ne))\n",
        "    print(\"-----------------------------------\")\n",
        "    print(confusion_matrix(y_ne, y_pred_ne))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aeaf6476",
      "metadata": {
        "id": "aeaf6476",
        "outputId": "f853bba2-3d00-4e70-8315-d4d4f20903aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===================================\n",
            "GradientBoostingClassifier(learning_rate=0.03880510732210184,\n",
            "                           loss='exponential', n_estimators=130)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.72      0.79       756\n",
            "           1       0.66      0.84      0.74       496\n",
            "\n",
            "    accuracy                           0.77      1252\n",
            "   macro avg       0.77      0.78      0.76      1252\n",
            "weighted avg       0.79      0.77      0.77      1252\n",
            "\n",
            "-----------------------------------\n",
            "[[543 213]\n",
            " [ 79 417]]\n",
            "===================================\n",
            "AdaBoostClassifier(learning_rate=0.05011872336272722, n_estimators=140)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.76      0.79       756\n",
            "           1       0.67      0.76      0.71       496\n",
            "\n",
            "    accuracy                           0.76      1252\n",
            "   macro avg       0.75      0.76      0.75      1252\n",
            "weighted avg       0.77      0.76      0.76      1252\n",
            "\n",
            "-----------------------------------\n",
            "[[573 183]\n",
            " [119 377]]\n",
            "===================================\n",
            "RandomForestClassifier(criterion='entropy', max_depth=10, n_estimators=130,\n",
            "                       n_jobs=-1)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.71      0.79       756\n",
            "           1       0.66      0.87      0.75       496\n",
            "\n",
            "    accuracy                           0.77      1252\n",
            "   macro avg       0.78      0.79      0.77      1252\n",
            "weighted avg       0.80      0.77      0.77      1252\n",
            "\n",
            "-----------------------------------\n",
            "[[533 223]\n",
            " [ 63 433]]\n",
            "===================================\n",
            "SVC(C=0.0107977516232771, degree=2)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.76      0.74       756\n",
            "           1       0.59      0.54      0.57       496\n",
            "\n",
            "    accuracy                           0.67      1252\n",
            "   macro avg       0.66      0.65      0.65      1252\n",
            "weighted avg       0.67      0.67      0.67      1252\n",
            "\n",
            "-----------------------------------\n",
            "[[572 184]\n",
            " [226 270]]\n"
          ]
        }
      ],
      "source": [
        "# Go search the rest of the data\n",
        "feat_co = pd.read_csv('acsincome_co_allfeaturesTP2.csv')\n",
        "label_co = pd.read_csv('acsincome_co_labelTP2.csv', usecols=['PINCP'])[['PINCP']]\n",
        "\n",
        "X_co, y_co = preprocess(feat_co, label_co)\n",
        "\n",
        "for model in best_models:\n",
        "    print(\"===================================\")\n",
        "    print(model)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_pred_co = model.predict(X_co)\n",
        "    print(classification_report(y_co, y_pred_co))\n",
        "    print(\"-----------------------------------\")\n",
        "    print(confusion_matrix(y_co, y_pred_co))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e1bdfdf",
      "metadata": {
        "id": "8e1bdfdf",
        "outputId": "e45a406f-0461-413e-fa55-7a18a2501a11"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>AGEP</th>\n",
              "      <td>0.264168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>COW</th>\n",
              "      <td>0.046983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SCHL</th>\n",
              "      <td>0.360586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MAR</th>\n",
              "      <td>-0.264910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OCCP</th>\n",
              "      <td>-0.348606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>POBP</th>\n",
              "      <td>-0.079059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RELP</th>\n",
              "      <td>-0.240801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>WKHP</th>\n",
              "      <td>0.352268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SEX</th>\n",
              "      <td>-0.132956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RAC1P</th>\n",
              "      <td>-0.112711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>target</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          target\n",
              "AGEP    0.264168\n",
              "COW     0.046983\n",
              "SCHL    0.360586\n",
              "MAR    -0.264910\n",
              "OCCP   -0.348606\n",
              "POBP   -0.079059\n",
              "RELP   -0.240801\n",
              "WKHP    0.352268\n",
              "SEX    -0.132956\n",
              "RAC1P  -0.112711\n",
              "target  1.000000"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X, y = preprocess(feat_raw, label_raw, 0.04)\n",
        "X['target'] = y\n",
        "\n",
        "X.corr()[['target']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cb49287",
      "metadata": {
        "id": "1cb49287",
        "outputId": "ece6f873-dcf2-4650-c142-06457118d0b7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pred_gb</th>\n",
              "      <th>pred_rf</th>\n",
              "      <th>pred_svm</th>\n",
              "      <th>pred_ab</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>AGEP</th>\n",
              "      <td>0.286628</td>\n",
              "      <td>0.285100</td>\n",
              "      <td>0.125453</td>\n",
              "      <td>0.216313</td>\n",
              "      <td>0.276761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>COW</th>\n",
              "      <td>0.085479</td>\n",
              "      <td>0.091218</td>\n",
              "      <td>0.057984</td>\n",
              "      <td>0.065155</td>\n",
              "      <td>0.060242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SCHL</th>\n",
              "      <td>0.461878</td>\n",
              "      <td>0.459632</td>\n",
              "      <td>0.372715</td>\n",
              "      <td>0.459879</td>\n",
              "      <td>0.295743</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MAR</th>\n",
              "      <td>-0.350799</td>\n",
              "      <td>-0.354088</td>\n",
              "      <td>-0.194431</td>\n",
              "      <td>-0.292840</td>\n",
              "      <td>-0.317111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OCCP</th>\n",
              "      <td>-0.511766</td>\n",
              "      <td>-0.506749</td>\n",
              "      <td>-0.774982</td>\n",
              "      <td>-0.564014</td>\n",
              "      <td>-0.328172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>POBP</th>\n",
              "      <td>-0.121493</td>\n",
              "      <td>-0.124791</td>\n",
              "      <td>-0.091928</td>\n",
              "      <td>-0.090622</td>\n",
              "      <td>-0.067688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RELP</th>\n",
              "      <td>-0.263641</td>\n",
              "      <td>-0.237894</td>\n",
              "      <td>-0.110511</td>\n",
              "      <td>-0.236787</td>\n",
              "      <td>-0.222336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>WKHP</th>\n",
              "      <td>0.428383</td>\n",
              "      <td>0.416074</td>\n",
              "      <td>0.170080</td>\n",
              "      <td>0.418060</td>\n",
              "      <td>0.353969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SEX</th>\n",
              "      <td>-0.105505</td>\n",
              "      <td>-0.116197</td>\n",
              "      <td>0.000220</td>\n",
              "      <td>-0.050292</td>\n",
              "      <td>-0.136962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RAC1P</th>\n",
              "      <td>-0.111471</td>\n",
              "      <td>-0.127051</td>\n",
              "      <td>-0.095535</td>\n",
              "      <td>-0.079429</td>\n",
              "      <td>-0.101184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_gb</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.908899</td>\n",
              "      <td>0.555244</td>\n",
              "      <td>0.887002</td>\n",
              "      <td>0.579672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_rf</th>\n",
              "      <td>0.908899</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.562023</td>\n",
              "      <td>0.832877</td>\n",
              "      <td>0.597743</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_svm</th>\n",
              "      <td>0.555244</td>\n",
              "      <td>0.562023</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.615838</td>\n",
              "      <td>0.368800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pred_ab</th>\n",
              "      <td>0.887002</td>\n",
              "      <td>0.832877</td>\n",
              "      <td>0.615838</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.542297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>target</th>\n",
              "      <td>0.579672</td>\n",
              "      <td>0.597743</td>\n",
              "      <td>0.368800</td>\n",
              "      <td>0.542297</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           pred_gb   pred_rf  pred_svm   pred_ab    target\n",
              "AGEP      0.286628  0.285100  0.125453  0.216313  0.276761\n",
              "COW       0.085479  0.091218  0.057984  0.065155  0.060242\n",
              "SCHL      0.461878  0.459632  0.372715  0.459879  0.295743\n",
              "MAR      -0.350799 -0.354088 -0.194431 -0.292840 -0.317111\n",
              "OCCP     -0.511766 -0.506749 -0.774982 -0.564014 -0.328172\n",
              "POBP     -0.121493 -0.124791 -0.091928 -0.090622 -0.067688\n",
              "RELP     -0.263641 -0.237894 -0.110511 -0.236787 -0.222336\n",
              "WKHP      0.428383  0.416074  0.170080  0.418060  0.353969\n",
              "SEX      -0.105505 -0.116197  0.000220 -0.050292 -0.136962\n",
              "RAC1P    -0.111471 -0.127051 -0.095535 -0.079429 -0.101184\n",
              "pred_gb   1.000000  0.908899  0.555244  0.887002  0.579672\n",
              "pred_rf   0.908899  1.000000  0.562023  0.832877  0.597743\n",
              "pred_svm  0.555244  0.562023  1.000000  0.615838  0.368800\n",
              "pred_ab   0.887002  0.832877  0.615838  1.000000  0.542297\n",
              "target    0.579672  0.597743  0.368800  0.542297  1.000000"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test_corr = X_test.copy()\n",
        "\n",
        "y_pred_GB = best_GB.predict(X_test)\n",
        "y_pred_RF = best_RF.predict(X_test)\n",
        "y_pred_SVM = best_SVM.predict(X_test)\n",
        "y_pred_AB = best_AB.predict(X_test)\n",
        "\n",
        "X_test_corr['pred_gb'] = y_pred_GB\n",
        "X_test_corr['pred_rf'] = y_pred_RF\n",
        "X_test_corr['pred_svm'] = y_pred_SVM\n",
        "X_test_corr['pred_ab'] = y_pred_AB\n",
        "X_test_corr['target'] = y_test\n",
        "\n",
        "X_test_corr.corr()[['pred_gb', 'pred_rf', 'pred_svm', 'pred_ab', 'target']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bc0043b",
      "metadata": {
        "id": "7bc0043b"
      },
      "outputs": [],
      "source": [
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "FIRF = permutation_importance(best_RF, X_train, y_train, n_repeats=10)\n",
        "FIGB = permutation_importance(best_GB, X_train, y_train, n_repeats=10)\n",
        "FISVM = permutation_importance(best_SVM, X_train, y_train, n_repeats=10)\n",
        "FIAB = permutation_importance(best_AB, X_train, y_train, n_repeats=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "550b8d83",
      "metadata": {
        "id": "550b8d83",
        "outputId": "165adac6-dc0d-4825-e00c-ae9b0795b08c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RandomForest\n",
            " [0.069377   0.01584665 0.07992013 0.01932907 0.09584665 0.02958466\n",
            " 0.03715655 0.1200639  0.01857827 0.00955272] \n",
            "\n",
            "\n",
            "GradientBoosting\n",
            " [3.86581470e-02 1.62939297e-03 5.43929712e-02 3.01916933e-03\n",
            " 4.98881789e-02 7.77955272e-03 1.74760383e-02 8.95527157e-02\n",
            " 8.09904153e-03 4.79233227e-05] \n",
            "\n",
            "\n",
            "SVM\n",
            " [0.         0.         0.         0.         0.18140575 0.\n",
            " 0.         0.         0.         0.        ] \n",
            "\n",
            "\n",
            "AdaBoost\n",
            " [0.02033546 0.         0.04455272 0.         0.04087859 0.00511182\n",
            " 0.01372204 0.07645367 0.00110224 0.        ] \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"RandomForest\\n\",FIRF.importances_mean, \"\\n\\n\")\n",
        "print(\"GradientBoosting\\n\",FIGB.importances_mean, \"\\n\\n\")\n",
        "print(\"SVM\\n\",FISVM.importances_mean, \"\\n\\n\")\n",
        "print(\"AdaBoost\\n\",FIAB.importances_mean, \"\\n\\n\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c375d3e",
      "metadata": {
        "id": "9c375d3e"
      },
      "source": [
        "# SENSITIVE DATA - SEX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de82be0d",
      "metadata": {
        "id": "de82be0d"
      },
      "outputs": [],
      "source": [
        "datamix = X_test.copy()\n",
        "datamix['label'] = y_test\n",
        "\n",
        "X_test_sex_M = datamix.loc[datamix.SEX == 1.0].drop(columns='label')\n",
        "X_test_sex_F = datamix.loc[datamix.SEX == 2.0].drop(columns='label')\n",
        "\n",
        "y_test_sex_M = datamix.loc[datamix.SEX == 1.0].label\n",
        "y_test_sex_F = datamix.loc[datamix.SEX == 2.0].label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7941eff3",
      "metadata": {
        "id": "7941eff3"
      },
      "outputs": [],
      "source": [
        "y_pred_GB_M = best_GB.predict(X_test_sex_M)\n",
        "y_pred_RF_M = best_RF.predict(X_test_sex_M)\n",
        "y_pred_SVM_M = best_SVM.predict(X_test_sex_M)\n",
        "y_pred_AB_M = best_AB.predict(X_test_sex_M)\n",
        "\n",
        "y_pred_GB_F = best_GB.predict(X_test_sex_F)\n",
        "y_pred_RF_F = best_RF.predict(X_test_sex_F)\n",
        "y_pred_SVM_F = best_SVM.predict(X_test_sex_F)\n",
        "y_pred_AB_F = best_AB.predict(X_test_sex_F)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e95ae74",
      "metadata": {
        "id": "0e95ae74",
        "outputId": "f5eee802-158d-409e-f645-f430e3fa2cda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "GB (M - F)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.79      0.80      0.79       461\n",
            "        True       0.76      0.75      0.75       396\n",
            "\n",
            "    accuracy                           0.77       857\n",
            "   macro avg       0.77      0.77      0.77       857\n",
            "weighted avg       0.77      0.77      0.77       857\n",
            "\n",
            "[[368  93]\n",
            " [100 296]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.88      0.85      0.87       477\n",
            "        True       0.72      0.77      0.74       232\n",
            "\n",
            "    accuracy                           0.83       709\n",
            "   macro avg       0.80      0.81      0.80       709\n",
            "weighted avg       0.83      0.83      0.83       709\n",
            "\n",
            "[[407  70]\n",
            " [ 54 178]]\n",
            "\n",
            "AB (M - F)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.74      0.83      0.78       461\n",
            "        True       0.77      0.66      0.71       396\n",
            "\n",
            "    accuracy                           0.75       857\n",
            "   macro avg       0.75      0.74      0.75       857\n",
            "weighted avg       0.75      0.75      0.75       857\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.88      0.85      0.87       477\n",
            "        True       0.71      0.75      0.73       232\n",
            "\n",
            "    accuracy                           0.82       709\n",
            "   macro avg       0.80      0.80      0.80       709\n",
            "weighted avg       0.82      0.82      0.82       709\n",
            "\n",
            "[[383  78]\n",
            " [136 260]]\n",
            "[[407  70]\n",
            " [ 57 175]]\n",
            "\n",
            "SVM (M - F)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.67      0.85      0.75       461\n",
            "        True       0.75      0.52      0.61       396\n",
            "\n",
            "    accuracy                           0.70       857\n",
            "   macro avg       0.71      0.68      0.68       857\n",
            "weighted avg       0.71      0.70      0.69       857\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.78      0.79      0.79       477\n",
            "        True       0.57      0.55      0.56       232\n",
            "\n",
            "    accuracy                           0.72       709\n",
            "   macro avg       0.68      0.67      0.67       709\n",
            "weighted avg       0.71      0.72      0.71       709\n",
            "\n",
            "[[392  69]\n",
            " [192 204]]\n",
            "[[379  98]\n",
            " [104 128]]\n",
            "\n",
            "RF (M - F)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.81      0.80      0.81       461\n",
            "        True       0.77      0.78      0.77       396\n",
            "\n",
            "    accuracy                           0.79       857\n",
            "   macro avg       0.79      0.79      0.79       857\n",
            "weighted avg       0.79      0.79      0.79       857\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.88      0.85      0.87       477\n",
            "        True       0.72      0.76      0.74       232\n",
            "\n",
            "    accuracy                           0.82       709\n",
            "   macro avg       0.80      0.81      0.80       709\n",
            "weighted avg       0.83      0.82      0.83       709\n",
            "\n",
            "[[371  90]\n",
            " [ 89 307]]\n",
            "[[407  70]\n",
            " [ 55 177]]\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nGB (M - F)\")\n",
        "print(classification_report(y_test_sex_M, y_pred_GB_M))\n",
        "print(confusion_matrix(y_test_sex_M, y_pred_GB_M))\n",
        "print(classification_report(y_test_sex_F, y_pred_GB_F))\n",
        "print(confusion_matrix(y_test_sex_F, y_pred_GB_F))\n",
        "\n",
        "print(\"\\nAB (M - F)\")\n",
        "print(classification_report(y_test_sex_M, y_pred_AB_M))\n",
        "print(classification_report(y_test_sex_F, y_pred_AB_F))\n",
        "print(confusion_matrix(y_test_sex_M, y_pred_AB_M))\n",
        "print(confusion_matrix(y_test_sex_F, y_pred_AB_F))\n",
        "\n",
        "print(\"\\nSVM (M - F)\")\n",
        "print(classification_report(y_test_sex_M, y_pred_SVM_M))\n",
        "print(classification_report(y_test_sex_F, y_pred_SVM_F))\n",
        "print(confusion_matrix(y_test_sex_M, y_pred_SVM_M))\n",
        "print(confusion_matrix(y_test_sex_F, y_pred_SVM_F))\n",
        "\n",
        "print(\"\\nRF (M - F)\")\n",
        "print(classification_report(y_test_sex_M, y_pred_RF_M))\n",
        "print(classification_report(y_test_sex_F, y_pred_RF_F))\n",
        "print(confusion_matrix(y_test_sex_M, y_pred_RF_M))\n",
        "print(confusion_matrix(y_test_sex_F, y_pred_RF_F))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42de4fd9",
      "metadata": {
        "id": "42de4fd9"
      },
      "outputs": [],
      "source": [
        " # acsincome_ca_features_without_sex\n",
        "# Go search the rest of the data\n",
        "feat_without_sex = pd.read_csv('acsincome_ca_features_without_sex.csv')\n",
        "X_WS, y_WS = preprocess(feat_without_sex, label_raw)\n",
        "\n",
        "X_WS_train, X_WS_test, y_WS_train, y_WS_test = train_test_split(X_WS, y_WS, test_size=0.2)\n",
        "y_WS_train = y_WS_train.to_numpy().reshape(1,-1)[0]\n",
        "\n",
        "for model in best_models:\n",
        "    model.fit(X_WS_train, y_WS_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d027cf3d",
      "metadata": {
        "id": "d027cf3d",
        "outputId": "ba4e546c-d9ff-4256-a50e-91c5827f6b14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===================================\n",
            "GradientBoostingClassifier(learning_rate=0.03880510732210184,\n",
            "                           loss='exponential', n_estimators=130)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.82      0.85      0.84       896\n",
            "        True       0.79      0.76      0.77       670\n",
            "\n",
            "    accuracy                           0.81      1566\n",
            "   macro avg       0.81      0.80      0.80      1566\n",
            "weighted avg       0.81      0.81      0.81      1566\n",
            "\n",
            "-----------------------------------\n",
            "[[760 136]\n",
            " [163 507]]\n",
            "===================================\n",
            "AdaBoostClassifier(learning_rate=0.05011872336272722, n_estimators=140)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.79      0.87      0.83       896\n",
            "        True       0.80      0.70      0.75       670\n",
            "\n",
            "    accuracy                           0.80      1566\n",
            "   macro avg       0.80      0.78      0.79      1566\n",
            "weighted avg       0.80      0.80      0.79      1566\n",
            "\n",
            "-----------------------------------\n",
            "[[779 117]\n",
            " [202 468]]\n",
            "===================================\n",
            "RandomForestClassifier(criterion='entropy', max_depth=10, n_estimators=130,\n",
            "                       n_jobs=-1)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.82      0.84      0.83       896\n",
            "        True       0.78      0.76      0.77       670\n",
            "\n",
            "    accuracy                           0.81      1566\n",
            "   macro avg       0.80      0.80      0.80      1566\n",
            "weighted avg       0.81      0.81      0.81      1566\n",
            "\n",
            "-----------------------------------\n",
            "[[756 140]\n",
            " [161 509]]\n",
            "===================================\n",
            "SVC(C=0.0107977516232771, degree=2)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.69      0.83      0.76       896\n",
            "        True       0.69      0.51      0.59       670\n",
            "\n",
            "    accuracy                           0.69      1566\n",
            "   macro avg       0.69      0.67      0.67      1566\n",
            "weighted avg       0.69      0.69      0.68      1566\n",
            "\n",
            "-----------------------------------\n",
            "[[743 153]\n",
            " [329 341]]\n"
          ]
        }
      ],
      "source": [
        "for model in best_models:\n",
        "    print(\"===================================\")\n",
        "    print(model)\n",
        "    y_pred = model.predict(X_WS_test)\n",
        "    print(classification_report(y_WS_test, y_pred))\n",
        "    print(\"-----------------------------------\")\n",
        "    print(confusion_matrix(y_WS_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3892c37b",
      "metadata": {
        "id": "3892c37b"
      },
      "source": [
        "Valeurs d’équité statistique - pas beaucoup de variation, 1% max ! c'est ok."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2896153d",
      "metadata": {
        "id": "2896153d"
      },
      "source": [
        "# SENSITIVE DATA - RAC1P"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75ee7e9b",
      "metadata": {
        "id": "75ee7e9b"
      },
      "outputs": [],
      "source": [
        "X, y = preprocess(feat_raw, label_raw)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "y_train = y_train.to_numpy().reshape(1,-1)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0247a6ab",
      "metadata": {
        "id": "0247a6ab",
        "outputId": "ef0c5fc0-0d7c-43d9-9449-6d36c735ae63"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([3865.,  292.,   52.,    0.,    0.,   13., 1031.,   22.,  713.,\n",
              "         272.]),\n",
              " array([1. , 1.8, 2.6, 3.4, 4.2, 5. , 5.8, 6.6, 7.4, 8.2, 9. ]),\n",
              " <BarContainer object of 10 artists>)"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.hist(X_train['RAC1P'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be0ecf7f",
      "metadata": {
        "id": "be0ecf7f"
      },
      "outputs": [],
      "source": [
        "datamix = X_test.copy()\n",
        "datamix['label'] = y_test\n",
        "\n",
        "X_test_race_cau = datamix.loc[datamix.RAC1P == 1.0].drop(columns='label')\n",
        "X_test_race_other = datamix.loc[datamix.RAC1P != 1.0].drop(columns='label')\n",
        "\n",
        "y_test_race_cau = datamix.loc[datamix.RAC1P == 1.0].label\n",
        "y_test_race_other = datamix.loc[datamix.RAC1P != 1.0].label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82b210d6",
      "metadata": {
        "id": "82b210d6"
      },
      "outputs": [],
      "source": [
        "best_GB = GradientBoostingClassifier(criterion='friedman_mse', learning_rate=0.03880510732210184,\n",
        "                                     loss='exponential', n_estimators=130)\n",
        "\n",
        "best_AB = AdaBoostClassifier(algorithm='SAMME.R', learning_rate=0.05011872336272722, n_estimators=140)\n",
        "\n",
        "best_RF = RandomForestClassifier(criterion='entropy', max_depth=10, min_samples_split=2, n_estimators=130, n_jobs=-1)\n",
        "\n",
        "best_SVM = SVC(C=0.0107977516232771, degree=2, kernel='rbf')\n",
        "\n",
        "best_models = [best_GB, best_AB, best_RF, best_SVM]\n",
        "\n",
        "for model in best_models:\n",
        "    model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "874c1d8a",
      "metadata": {
        "id": "874c1d8a"
      },
      "outputs": [],
      "source": [
        "y_pred_GB_cau = best_GB.predict(X_test_race_cau)\n",
        "y_pred_RF_cau = best_RF.predict(X_test_race_cau)\n",
        "y_pred_SVM_cau = best_SVM.predict(X_test_race_cau)\n",
        "y_pred_AB_cau = best_AB.predict(X_test_race_cau)\n",
        "\n",
        "y_pred_GB_other = best_GB.predict(X_test_race_other)\n",
        "y_pred_RF_other = best_RF.predict(X_test_race_other)\n",
        "y_pred_SVM_other = best_SVM.predict(X_test_race_other)\n",
        "y_pred_AB_other = best_AB.predict(X_test_race_other)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8f61d88",
      "metadata": {
        "id": "d8f61d88",
        "outputId": "1b274e68-6c97-42d2-ab72-7da5045c3b7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "GB (caucasian - other)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.82      0.85      0.84       531\n",
            "        True       0.80      0.77      0.79       419\n",
            "\n",
            "    accuracy                           0.81       950\n",
            "   macro avg       0.81      0.81      0.81       950\n",
            "weighted avg       0.81      0.81      0.81       950\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.86      0.89      0.88       409\n",
            "        True       0.77      0.71      0.74       207\n",
            "\n",
            "    accuracy                           0.83       616\n",
            "   macro avg       0.81      0.80      0.81       616\n",
            "weighted avg       0.83      0.83      0.83       616\n",
            "\n",
            "\n",
            "AB (caucasian - other)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.79      0.89      0.83       531\n",
            "        True       0.83      0.70      0.76       419\n",
            "\n",
            "    accuracy                           0.80       950\n",
            "   macro avg       0.81      0.79      0.80       950\n",
            "weighted avg       0.81      0.80      0.80       950\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.85      0.90      0.88       409\n",
            "        True       0.79      0.69      0.74       207\n",
            "\n",
            "    accuracy                           0.83       616\n",
            "   macro avg       0.82      0.80      0.81       616\n",
            "weighted avg       0.83      0.83      0.83       616\n",
            "\n",
            "\n",
            "SVM (caucasian - other)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.69      0.89      0.77       531\n",
            "        True       0.77      0.49      0.60       419\n",
            "\n",
            "    accuracy                           0.71       950\n",
            "   macro avg       0.73      0.69      0.69       950\n",
            "weighted avg       0.73      0.71      0.70       950\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.78      0.86      0.82       409\n",
            "        True       0.66      0.52      0.58       207\n",
            "\n",
            "    accuracy                           0.75       616\n",
            "   macro avg       0.72      0.69      0.70       616\n",
            "weighted avg       0.74      0.75      0.74       616\n",
            "\n",
            "\n",
            "RF (caucasian - other)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.84      0.82      0.83       531\n",
            "        True       0.78      0.81      0.79       419\n",
            "\n",
            "    accuracy                           0.82       950\n",
            "   macro avg       0.81      0.81      0.81       950\n",
            "weighted avg       0.82      0.82      0.82       950\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.86      0.90      0.88       409\n",
            "        True       0.79      0.72      0.75       207\n",
            "\n",
            "    accuracy                           0.84       616\n",
            "   macro avg       0.83      0.81      0.82       616\n",
            "weighted avg       0.84      0.84      0.84       616\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nGB (caucasian - other)\")\n",
        "print(classification_report(y_test_race_cau, y_pred_GB_cau))\n",
        "print(classification_report(y_test_race_other, y_pred_GB_other))\n",
        "\n",
        "print(\"\\nAB (caucasian - other)\")\n",
        "print(classification_report(y_test_race_cau, y_pred_AB_cau))\n",
        "print(classification_report(y_test_race_other, y_pred_AB_other))\n",
        "\n",
        "print(\"\\nSVM (caucasian - other)\")\n",
        "print(classification_report(y_test_race_cau, y_pred_SVM_cau))\n",
        "print(classification_report(y_test_race_other, y_pred_SVM_other))\n",
        "\n",
        "print(\"\\nRF (caucasian - other)\")\n",
        "print(classification_report(y_test_race_cau, y_pred_RF_cau))\n",
        "print(classification_report(y_test_race_other, y_pred_RF_other))"
      ]
    },
    {
      "cell_type": "raw",
      "id": "5a62806f",
      "metadata": {
        "id": "5a62806f"
      },
      "source": [
        "RF et GB : se trompent + pour les non blancs (8% diff GB et 10% RF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "321f33af",
      "metadata": {
        "id": "321f33af"
      },
      "outputs": [],
      "source": [
        "# Go search the rest of the data (without race) and test\n",
        "feat_without_race = pd.read_csv('acsincome_ca_features_without_race.csv')\n",
        "X_WR, y_WR = preprocess(feat_without_race, label_raw)\n",
        "\n",
        "X_WR_train, X_WR_test, y_WR_train, y_WR_test = train_test_split(X_WR, y_WR, test_size=0.2)\n",
        "y_WR_train = y_WR_train.to_numpy().reshape(1,-1)[0]\n",
        "\n",
        "for model in best_models:\n",
        "    model.fit(X_WR_train, y_WR_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f760015d",
      "metadata": {
        "id": "f760015d",
        "outputId": "62f21a65-74de-4bf0-925a-b9f369a62522"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===================================\n",
            "GradientBoostingClassifier(learning_rate=0.03880510732210184,\n",
            "                           loss='exponential', n_estimators=130)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.82      0.87      0.85       880\n",
            "        True       0.82      0.76      0.79       686\n",
            "\n",
            "    accuracy                           0.82      1566\n",
            "   macro avg       0.82      0.81      0.82      1566\n",
            "weighted avg       0.82      0.82      0.82      1566\n",
            "\n",
            "-----------------------------------\n",
            "[[764 116]\n",
            " [164 522]]\n",
            "===================================\n",
            "AdaBoostClassifier(learning_rate=0.05011872336272722, n_estimators=140)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.79      0.89      0.84       880\n",
            "        True       0.83      0.70      0.76       686\n",
            "\n",
            "    accuracy                           0.81      1566\n",
            "   macro avg       0.81      0.80      0.80      1566\n",
            "weighted avg       0.81      0.81      0.80      1566\n",
            "\n",
            "-----------------------------------\n",
            "[[780 100]\n",
            " [203 483]]\n",
            "===================================\n",
            "RandomForestClassifier(criterion='entropy', max_depth=10, n_estimators=130,\n",
            "                       n_jobs=-1)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.83      0.85      0.84       880\n",
            "        True       0.80      0.78      0.79       686\n",
            "\n",
            "    accuracy                           0.82      1566\n",
            "   macro avg       0.82      0.82      0.82      1566\n",
            "weighted avg       0.82      0.82      0.82      1566\n",
            "\n",
            "-----------------------------------\n",
            "[[750 130]\n",
            " [152 534]]\n",
            "===================================\n",
            "SVC(C=0.0107977516232771, degree=2)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.69      0.86      0.77       880\n",
            "        True       0.74      0.51      0.61       686\n",
            "\n",
            "    accuracy                           0.71      1566\n",
            "   macro avg       0.72      0.69      0.69      1566\n",
            "weighted avg       0.71      0.71      0.70      1566\n",
            "\n",
            "-----------------------------------\n",
            "[[754 126]\n",
            " [333 353]]\n"
          ]
        }
      ],
      "source": [
        "for model in best_models:\n",
        "    print(\"===================================\")\n",
        "    print(model)\n",
        "    y_pred = model.predict(X_WR_test)\n",
        "    print(classification_report(y_WR_test, y_pred))\n",
        "    print(\"-----------------------------------\")\n",
        "    print(confusion_matrix(y_WR_test, y_pred))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}